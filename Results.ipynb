{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import flownet as fl\n",
    "import goes16s3\n",
    "import utils\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import scipy\n",
    "import math\n",
    "from skimage.measure import compare_ssim\n",
    "\n",
    "font = {'family' : 'times',\n",
    "        'size'   : 16}\n",
    "\n",
    "matplotlib.rc('font', **font)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Figures\n",
    "\n",
    "##  1: Dataset Examples\n",
    "\n",
    "##  2: Network Architecture\n",
    "\n",
    "Network architecture as shown in slomo, including the multi-variate case. <br>\n",
    "Flow and Intermediate Interpolation Networks. Can we use example input and flow images to represent it? I think so.\n",
    "\n",
    "##  3: Optical flows of a test example\n",
    "1. I0, I1, and It\n",
    "2. Flows: F_01, F_10, F_01_delta, F_10_delta\n",
    "3. Visible: V0 and V1\n",
    "4. Difference between I0 and I1\n",
    "\n",
    "## Figure 4: Time dependent errors\n",
    "1. Linear interpolation\n",
    "2. SloMo\n",
    "3. MV-SloMo\n",
    "\n",
    "# Tables\n",
    "## 1: Overall and Per band errors\n",
    "1, 3, 5, and 8 band experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_models(n_channels, model_path, multivariate=False):\n",
    "    \n",
    "    if multivariate:\n",
    "        model_filename = os.path.join(model_path, 'checkpoint.flownet.mv.pth.tar')\n",
    "        flownet = fl.SloMoFlowNetMV(n_channels)#.cuda()\n",
    "        interpnet = fl.SloMoInterpNetMV(n_channels)#.cuda()\n",
    "    else:\n",
    "        model_filename = os.path.join(model_path, 'checkpoint.flownet.pth.tar')\n",
    "        flownet = fl.SloMoFlowNet(n_channels)#.cuda()\n",
    "        interpnet = fl.SloMoInterpNet(n_channels)#.cuda()\n",
    "        \n",
    "    warper = fl.FlowWarper()\n",
    "    \n",
    "    flownet = flownet.to(device)\n",
    "    interpnet = interpnet.to(device)\n",
    "    warper = warper.to(device)\n",
    "\n",
    "    def load_checkpoint(flownet, interpnet):\n",
    "        epoch = 0\n",
    "        if os.path.isfile(model_filename):\n",
    "            print(\"loading checkpoint %s\" % model_filename)\n",
    "            checkpoint = torch.load(model_filename)\n",
    "            flownet.load_state_dict(checkpoint['flownet_state_dict'])\n",
    "            interpnet.load_state_dict(checkpoint['interpnet_state_dict'])\n",
    "            epoch = checkpoint['epoch']\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                    .format(model_filename, epoch))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(model_filename))\n",
    "        return flownet, interpnet\n",
    "\n",
    "    flownet.train()\n",
    "    interpnet.train()\n",
    "    flownet, interpnet = load_checkpoint(flownet, interpnet)\n",
    "    return flownet, interpnet, warper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint ./saved-models/5Min-1Channels/checkpoint.flownet.pth.tar\n",
      "=> loaded checkpoint './saved-models/5Min-1Channels/checkpoint.flownet.pth.tar' (epoch 21)\n"
     ]
    }
   ],
   "source": [
    "year = 2018\n",
    "# Noreaster\n",
    "\n",
    "days = [#datetime(year, 3, 3).timetuple().tm_yday, # Noreaster\n",
    "        datetime(year, 7, 18).timetuple().tm_yday,]\n",
    "\n",
    "channels = [1,3,5,8]\n",
    "\n",
    "\n",
    "\n",
    "day = days[0]\n",
    "n_channels = channels[0]\n",
    "multivariate = True\n",
    "\n",
    "if n_channels == 1:\n",
    "    multivariate = False\n",
    "    \n",
    "model_path = './saved-models/5Min-%iChannels/' % n_channels\n",
    "\n",
    "flownet, interpnet, warper = load_models(n_channels,model_path, multivariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inference for channel 1, year 2018, and day 199\n",
      "loading checkpoint ./saved-models/5Min-1Channels/checkpoint.flownet.pth.tar\n",
      "=> loaded checkpoint './saved-models/5Min-1Channels/checkpoint.flownet.pth.tar' (epoch 21)\n",
      "('Day', 199, 'Hour', 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tj/.local/lib/python2.7/site-packages/ipykernel_launcher.py:52: FutureWarning: the `dim` argument to `concat` will be required in a future version of xarray; for now, setting it to the old default of 'concat_dim'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_00.nc\n",
      "('Day', 199, 'Hour', 13)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_01.nc\n",
      "('Day', 199, 'Hour', 14)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_02.nc\n",
      "('Day', 199, 'Hour', 15)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_03.nc\n",
      "('Day', 199, 'Hour', 16)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_04.nc\n",
      "('Day', 199, 'Hour', 17)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_05.nc\n",
      "('Day', 199, 'Hour', 18)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_06.nc\n",
      "('Day', 199, 'Hour', 19)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_07.nc\n",
      "('Day', 199, 'Hour', 20)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_08.nc\n",
      "('Day', 199, 'Hour', 21)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_09.nc\n",
      "('Day', 199, 'Hour', 22)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_10.nc\n",
      "('Day', 199, 'Hour', 23)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_11.nc\n",
      "('Day', 199, 'Hour', 12)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_12.nc\n",
      "('Day', 199, 'Hour', 13)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_13.nc\n",
      "('Day', 199, 'Hour', 14)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_14.nc\n",
      "('Day', 199, 'Hour', 15)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_15.nc\n",
      "('Day', 199, 'Hour', 16)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_16.nc\n",
      "('Day', 199, 'Hour', 17)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_17.nc\n",
      "('Day', 199, 'Hour', 18)\n",
      "x Indicies do not match\n",
      "('Day', 199, 'Hour', 19)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_18.nc\n",
      "('Day', 199, 'Hour', 20)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_19.nc\n",
      "('Day', 199, 'Hour', 21)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_20.nc\n",
      "('Day', 199, 'Hour', 22)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_21.nc\n",
      "('Day', 199, 'Hour', 23)\n",
      "Saved to file: ./saved-models/5Min-1Channels/2018_199/2018_199_22.nc\n",
      "Test inference for channel 3, year 2018, and day 199\n",
      "loading checkpoint ./saved-models/5Min-3Channels/checkpoint.flownet.pth.tar\n",
      "=> loaded checkpoint './saved-models/5Min-3Channels/checkpoint.flownet.pth.tar' (epoch 19)\n",
      "loading checkpoint ./saved-models/5Min-3Channels/checkpoint.flownet.mv.pth.tar\n",
      "=> loaded checkpoint './saved-models/5Min-3Channels/checkpoint.flownet.mv.pth.tar' (epoch 19)\n",
      "('Day', 199, 'Hour', 12)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_00.nc\n",
      "('Day', 199, 'Hour', 13)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_01.nc\n",
      "('Day', 199, 'Hour', 14)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_02.nc\n",
      "('Day', 199, 'Hour', 15)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_03.nc\n",
      "('Day', 199, 'Hour', 16)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_04.nc\n",
      "('Day', 199, 'Hour', 17)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_05.nc\n",
      "('Day', 199, 'Hour', 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tj/.local/lib/python2.7/site-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in less\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/tj/.local/lib/python2.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in greater\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_06.nc\n",
      "('Day', 199, 'Hour', 19)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_07.nc\n",
      "('Day', 199, 'Hour', 20)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_08.nc\n",
      "('Day', 199, 'Hour', 21)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_09.nc\n",
      "('Day', 199, 'Hour', 22)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_10.nc\n",
      "('Day', 199, 'Hour', 23)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_11.nc\n",
      "('Day', 199, 'Hour', 12)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_12.nc\n",
      "('Day', 199, 'Hour', 13)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_13.nc\n",
      "('Day', 199, 'Hour', 14)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_14.nc\n",
      "('Day', 199, 'Hour', 15)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_15.nc\n",
      "('Day', 199, 'Hour', 16)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_16.nc\n",
      "('Day', 199, 'Hour', 17)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_17.nc\n",
      "('Day', 199, 'Hour', 18)\n",
      "x Indicies do not match\n",
      "('Day', 199, 'Hour', 19)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_18.nc\n",
      "('Day', 199, 'Hour', 20)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_19.nc\n",
      "('Day', 199, 'Hour', 21)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_20.nc\n",
      "('Day', 199, 'Hour', 22)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_21.nc\n",
      "('Day', 199, 'Hour', 23)\n",
      "Saved to file: ./saved-models/5Min-3Channels/2018_199/2018_199_22.nc\n",
      "Test inference for channel 5, year 2018, and day 199\n",
      "loading checkpoint ./saved-models/5Min-5Channels/checkpoint.flownet.pth.tar\n",
      "=> loaded checkpoint './saved-models/5Min-5Channels/checkpoint.flownet.pth.tar' (epoch 19)\n",
      "loading checkpoint ./saved-models/5Min-5Channels/checkpoint.flownet.mv.pth.tar\n",
      "=> loaded checkpoint './saved-models/5Min-5Channels/checkpoint.flownet.mv.pth.tar' (epoch 19)\n",
      "('Day', 199, 'Hour', 12)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_00.nc\n",
      "('Day', 199, 'Hour', 13)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_01.nc\n",
      "('Day', 199, 'Hour', 14)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_02.nc\n",
      "('Day', 199, 'Hour', 15)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_03.nc\n",
      "('Day', 199, 'Hour', 16)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_04.nc\n",
      "('Day', 199, 'Hour', 17)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_05.nc\n",
      "('Day', 199, 'Hour', 18)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_06.nc\n",
      "('Day', 199, 'Hour', 19)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_07.nc\n",
      "('Day', 199, 'Hour', 20)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_08.nc\n",
      "('Day', 199, 'Hour', 21)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_09.nc\n",
      "('Day', 199, 'Hour', 22)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_10.nc\n",
      "('Day', 199, 'Hour', 23)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_11.nc\n",
      "('Day', 199, 'Hour', 12)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_12.nc\n",
      "('Day', 199, 'Hour', 13)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_13.nc\n",
      "('Day', 199, 'Hour', 14)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_14.nc\n",
      "('Day', 199, 'Hour', 15)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_15.nc\n",
      "('Day', 199, 'Hour', 16)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_16.nc\n",
      "('Day', 199, 'Hour', 17)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_17.nc\n",
      "('Day', 199, 'Hour', 18)\n",
      "x Indicies do not match\n",
      "('Day', 199, 'Hour', 19)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_18.nc\n",
      "('Day', 199, 'Hour', 20)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_19.nc\n",
      "('Day', 199, 'Hour', 21)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_20.nc\n",
      "('Day', 199, 'Hour', 22)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_21.nc\n",
      "('Day', 199, 'Hour', 23)\n",
      "Saved to file: ./saved-models/5Min-5Channels/2018_199/2018_199_22.nc\n",
      "Test inference for channel 8, year 2018, and day 199\n",
      "loading checkpoint ./saved-models/5Min-8Channels/checkpoint.flownet.pth.tar\n",
      "=> loaded checkpoint './saved-models/5Min-8Channels/checkpoint.flownet.pth.tar' (epoch 19)\n",
      "loading checkpoint ./saved-models/5Min-8Channels/checkpoint.flownet.mv.pth.tar\n",
      "=> loaded checkpoint './saved-models/5Min-8Channels/checkpoint.flownet.mv.pth.tar' (epoch 19)\n",
      "('Day', 199, 'Hour', 12)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_00.nc\n",
      "('Day', 199, 'Hour', 13)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_01.nc\n",
      "('Day', 199, 'Hour', 14)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_02.nc\n",
      "('Day', 199, 'Hour', 15)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_03.nc\n",
      "('Day', 199, 'Hour', 16)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_04.nc\n",
      "('Day', 199, 'Hour', 17)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_05.nc\n",
      "('Day', 199, 'Hour', 18)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_06.nc\n",
      "('Day', 199, 'Hour', 19)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_07.nc\n",
      "('Day', 199, 'Hour', 20)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_08.nc\n",
      "('Day', 199, 'Hour', 21)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_09.nc\n",
      "('Day', 199, 'Hour', 22)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_10.nc\n",
      "('Day', 199, 'Hour', 23)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_11.nc\n",
      "('Day', 199, 'Hour', 12)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_12.nc\n",
      "('Day', 199, 'Hour', 13)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_13.nc\n",
      "('Day', 199, 'Hour', 14)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_14.nc\n",
      "('Day', 199, 'Hour', 15)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_15.nc\n",
      "('Day', 199, 'Hour', 16)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_16.nc\n",
      "('Day', 199, 'Hour', 17)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_17.nc\n",
      "('Day', 199, 'Hour', 18)\n",
      "x Indicies do not match\n",
      "('Day', 199, 'Hour', 19)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_18.nc\n",
      "('Day', 199, 'Hour', 20)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_19.nc\n",
      "('Day', 199, 'Hour', 21)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_20.nc\n",
      "('Day', 199, 'Hour', 22)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_21.nc\n",
      "('Day', 199, 'Hour', 23)\n",
      "Saved to file: ./saved-models/5Min-8Channels/2018_199/2018_199_22.nc\n"
     ]
    }
   ],
   "source": [
    "def block_predictions_to_dataarray(predictions, block):\n",
    "    block_predictions = np.concatenate(predictions, 0)\n",
    "    block_predictions[block_predictions < 0] = 0\n",
    "    block_predictions[block_predictions > 1] = 1\n",
    "\n",
    "    N_pred = block_predictions.shape[0]\n",
    "    da = xr.DataArray(block_predictions,#[:,:,shave:-shave,shave:-shave],\n",
    "              coords=[block.t.values[:N_pred], block.band.values,\n",
    "                      block.y.values,#[shave:-shave], \n",
    "                      block.x.values,],#][shave:-shave]],\n",
    "              dims=['t', 'band', 'y', 'x'])\n",
    "\n",
    "    return da\n",
    "\n",
    "def inference(block, flownet, interpnet, warper, multivariate):\n",
    "    block_vals = torch.from_numpy(block.values)\n",
    "    N = block_vals.shape[0]\n",
    "    idxs = np.arange(0, N+1, 5)\n",
    "    preds = []\n",
    "    for idx0, idx1 in zip(idxs[:-1], idxs[1:]):\n",
    "        idx1 = min(N-1, idx1)\n",
    "        I0 = torch.unsqueeze(block_vals[idx0], 0).to(device)\n",
    "        I1 = torch.unsqueeze(block_vals[idx1], 0).to(device)\n",
    "\n",
    "        f = flownet(I0, I1)\n",
    "        n_channels = I0.shape[1]\n",
    "        \n",
    "        if multivariate:\n",
    "            f_01 = f[:,:2*n_channels]\n",
    "            f_10 = f[:,2*n_channels:]\n",
    "        else:\n",
    "            f_01 = f[:,:2]\n",
    "            f_10 = f[:,2:]\n",
    "\n",
    "        T = idx1 - idx0 - 1\n",
    "        predicted_frames = []\n",
    "        for j in range(1,T+1):\n",
    "            t = 1. * j / (T+1)\n",
    "            I_t, g0, g1, V_t0, V_t1, delta_f_t0, delta_f_t1 = interpnet(I0, I1, f_01, f_10, t)\n",
    "            predicted_frames.append(I_t.cpu().detach().numpy())\n",
    "        \n",
    "        preds += [I0.cpu().numpy()] + predicted_frames\n",
    "            \n",
    "    return block_predictions_to_dataarray(preds, block)\n",
    "\n",
    "def merge_and_average_dataarrays(dataarrays):\n",
    "    ds = xr.merge([xr.Dataset({k: d}) for k, d in enumerate(dataarrays)])\n",
    "    das = []\n",
    "    for b in range(0,len(dataarrays)):\n",
    "        das.append(ds[b])\n",
    "\n",
    "    return xr.concat(das).mean('concat_dims', skipna=True)\n",
    "\n",
    "def testset_inference(n_channels, year, day):\n",
    "    model_path = './saved-models/5Min-%iChannels/' % n_channels\n",
    "    flownet, interpnet, warper = load_models(n_channels, model_path, False)\n",
    "    if n_channels > 1:\n",
    "        flownetmv, interpnetmv, warpermv = load_models(n_channels, model_path, True)\n",
    "\n",
    "        \n",
    "    dataset = goes16s3.NOAAGOESS3(product='ABI-L1b-RadM', \n",
    "                                  channels=range(1,n_channels+1))\n",
    "\n",
    "    saved_data_files = []\n",
    "    for houri, hour_das in enumerate(dataset.read_day(year, day)): # N,12or13,512,512,3\n",
    "        blocked_data = utils.blocks(hour_das, width=352)\n",
    "        sv_interpolated_hour, mv_interpolated_hour = [], []\n",
    "        for block_num, block in enumerate(blocked_data):            \n",
    "            sv_da = inference(block, flownet, interpnet, warper, False)\n",
    "            sv_interpolated_hour.append(sv_da)\n",
    "            if n_channels > 1:\n",
    "                mv_da = inference(block, flownetmv, interpnetmv, warpermv, True)\n",
    "                mv_interpolated_hour.append(mv_da)\n",
    "\n",
    "        sv_prediction_da = merge_and_average_dataarrays(sv_interpolated_hour)\n",
    "        ds = xr.Dataset({'observed': hour_das, 'sv_predicted': sv_prediction_da})\n",
    "        if n_channels > 1:\n",
    "            ds['mv_predicted'] = merge_and_average_dataarrays(mv_interpolated_hour)\n",
    "        ncpath = os.path.join(model_path, '%04i_%03i' % (year, day))\n",
    "        if not os.path.exists(ncpath):\n",
    "            os.mkdir(ncpath)\n",
    "        ncfile = os.path.join(ncpath,  '%04i_%03i_%02i.nc' % (year, day, houri))\n",
    "\n",
    "        print(\"Saved to file: {}\".format(ncfile))\n",
    "        ds.to_netcdf(ncfile)\n",
    "        saved_data_files.append(ncfile)\n",
    "        \n",
    "#for c in channels:\n",
    "for c in [1,3,5,8]:\n",
    "    for day in days:\n",
    "        print(\"Test inference for channel {}, year 2018, and day {}\".format(c, day))\n",
    "        testset_inference(c, 2018, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(img1, img2, axis=None):\n",
    "    img1[img1 == np.inf] = np.nan\n",
    "    img2[img2 == np.inf] = np.nan\n",
    "    \n",
    "    mse = np.nanmean((img1 - img2) ** 2, axis=axis)\n",
    "    \n",
    "    #print('obs', np.histogram(img2.flatten(),\n",
    "    #                range=[np.nanmin(img2), np.nanmax(img2)]))\n",
    "    #if isinstance(mse, float) and mse == 0:\n",
    "    #    return 100\n",
    "    if np.any(mse[mse == np.inf]):\n",
    "        return np.zeros_like(mse)\n",
    "    \n",
    "    #if isinstance(mse, float) and mse == np.inf:\n",
    "    #    return None\n",
    "\n",
    "    PIXEL_MAX = 1.0\n",
    "    return 20 * np.log10(PIXEL_MAX / np.sqrt(mse))\n",
    "\n",
    "\n",
    "def ssim(img1, img2):\n",
    "    img1[img1 == np.inf] = np.nan\n",
    "    img2[img2 == np.inf] = np.nan\n",
    "    \n",
    "    img1[np.isnan(img1)] = 0.\n",
    "    img2[np.isnan(img2)] = 0.\n",
    "    r = []\n",
    "    for b in range(img1.shape[1]):\n",
    "        sms = [compare_ssim(img1[i,b], img2[i,b]) for i in range(img1.shape[0])]\n",
    "        r.append(np.nanmean(sms))\n",
    "    return np.array(r)\n",
    "\n",
    "#def bandwise_psnr(img1, img2): # assuming (t,c,h,w)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved-models/5Min-1Channels/2018_199/2018_199_00.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_01.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_02.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_03.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_04.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_05.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_06.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_07.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_08.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_09.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_10.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_11.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_12.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_13.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_14.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_15.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_16.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_17.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_18.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_19.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_20.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_21.nc\n",
      "./saved-models/5Min-1Channels/2018_199/2018_199_22.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_00.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_01.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_02.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_03.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_04.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_05.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_06.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_07.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_08.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_09.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_10.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_11.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_12.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_13.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_14.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_15.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_16.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_17.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_18.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_19.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_20.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_21.nc\n",
      "./saved-models/5Min-3Channels/2018_199/2018_199_22.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_00.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_01.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_02.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_03.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_04.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_05.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_06.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_07.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_08.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_09.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_10.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_11.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_12.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_13.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_14.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_15.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_16.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_17.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_18.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_19.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_20.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_21.nc\n",
      "./saved-models/5Min-5Channels/2018_199/2018_199_22.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_00.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_01.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_02.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_03.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_04.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_05.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_06.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_07.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_08.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_09.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_10.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_11.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_12.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_13.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_14.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_15.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_16.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_17.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_18.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_19.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_20.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_21.nc\n",
      "./saved-models/5Min-8Channels/2018_199/2018_199_22.nc\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for c in [1,3,5,8]:\n",
    "    model_path = './saved-models/5Min-%iChannels/2018_199/' % c\n",
    "    saved_data_files = sorted([os.path.join(model_path, f) \n",
    "                        for f in os.listdir(model_path) if f[-3:] == '.nc'])\n",
    "    for sf in saved_data_files:\n",
    "        print(sf)\n",
    "        ds = xr.open_dataset(sf)        \n",
    "        svpsnr = psnr(ds.sv_predicted.values, ds.observed.values, (3,2,0))\n",
    "        svssim = ssim(ds.sv_predicted.values, ds.observed.values)\n",
    "        if c > 1:\n",
    "            mvpsnr = psnr(ds.mv_predicted.values, ds.observed.values, (3,2,0))\n",
    "            mvssim = ssim(ds.mv_predicted.values, ds.observed.values)\n",
    "        else:\n",
    "            mvpsnr = [None]*len(svpsnr)\n",
    "            mvssim = [None]*len(svpsnr)\n",
    "\n",
    "        for b in range(len(svpsnr)):\n",
    "            r = {'Channels': c, 'Band': b+1, 'Model': 'A-Single', 'PSNR': svpsnr[b], 'SSIM': svssim[b]}\n",
    "            results.append(r)\n",
    "            r = {'Channels': c, 'Band': b+1, 'Model': 'B-Multi', 'PSNR': mvpsnr[b], 'SSIM': mvssim[b]}\n",
    "            results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels          1          3                     5                     8  \\\n",
      "Model      A-Single   A-Single    B-Multi   A-Single    B-Multi   A-Single   \n",
      "Band                                                                         \n",
      "1         35.706924  35.088647  35.088176  34.888095  35.286151  34.395813   \n",
      "2               NaN  31.464401  31.327234  31.398013  31.498074  31.075731   \n",
      "3               NaN  34.257125  34.356584  34.119461  34.449316  33.674573   \n",
      "4               NaN        NaN        NaN  40.777740  40.652763  40.606444   \n",
      "5               NaN        NaN        NaN  31.716171  31.774259  31.323608   \n",
      "6               NaN        NaN        NaN        NaN        NaN  33.676186   \n",
      "7               NaN        NaN        NaN        NaN        NaN  35.723391   \n",
      "8               NaN        NaN        NaN        NaN        NaN  42.826030   \n",
      "\n",
      "Channels             \n",
      "Model       B-Multi  \n",
      "Band                 \n",
      "1         34.703941  \n",
      "2         31.047545  \n",
      "3         33.927057  \n",
      "4         40.273549  \n",
      "5         31.428938  \n",
      "6         33.935538  \n",
      "7         35.371702  \n",
      "8         42.644412  \n",
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "Channels &        1 & \\multicolumn{2}{l}{3} & \\multicolumn{2}{l}{5} & \\multicolumn{2}{l}{8} \\\\\n",
      "Model & A-Single & A-Single & B-Multi & A-Single & B-Multi & A-Single & B-Multi \\\\\n",
      "Band &          &          &         &          &         &          &         \\\\\n",
      "\\midrule\n",
      "1    &    35.71 &    35.09 &   35.09 &    34.89 &   35.29 &    34.40 &   34.70 \\\\\n",
      "2    &      nan &    31.46 &   31.33 &    31.40 &   31.50 &    31.08 &   31.05 \\\\\n",
      "3    &      nan &    34.26 &   34.36 &    34.12 &   34.45 &    33.67 &   33.93 \\\\\n",
      "4    &      nan &      nan &     nan &    40.78 &   40.65 &    40.61 &   40.27 \\\\\n",
      "5    &      nan &      nan &     nan &    31.72 &   31.77 &    31.32 &   31.43 \\\\\n",
      "6    &      nan &      nan &     nan &      nan &     nan &    33.68 &   33.94 \\\\\n",
      "7    &      nan &      nan &     nan &      nan &     nan &    35.72 &   35.37 \\\\\n",
      "8    &      nan &      nan &     nan &      nan &     nan &    42.83 &   42.64 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "Model      A-Single    B-Multi\n",
      "Channels                      \n",
      "1         35.706924        NaN\n",
      "3         33.603391  33.590665\n",
      "5         34.579896  34.732113\n",
      "8         35.412722  35.416585\n",
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "Model &  A-Single &  B-Multi \\\\\n",
      "Channels &           &          \\\\\n",
      "\\midrule\n",
      "1        &     35.71 &      nan \\\\\n",
      "3        &     33.60 &    33.59 \\\\\n",
      "5        &     34.58 &    34.73 \\\\\n",
      "8        &     35.41 &    35.42 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.set_index([\"Channels\", \"Band\", \"Model\"])\n",
    "psnr_per_band_table = pd.pivot_table(results_df, values='PSNR', index=['Band'], \n",
    "                       columns=['Channels', 'Model'])\n",
    "\n",
    "print(psnr_per_band_table)\n",
    "reslatex = psnr_per_band_table.to_latex(float_format='{:,.2f}'.format)\n",
    "print(reslatex)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.set_index([\"Channels\", \"Band\", \"Model\"])\n",
    "psnr_per_band_table = pd.pivot_table(results_df, values='PSNR', index=['Channels'], \n",
    "                       columns=['Model'])\n",
    "\n",
    "print(psnr_per_band_table)\n",
    "reslatex = psnr_per_band_table.to_latex(float_format='{:,.2f}'.format)\n",
    "print(reslatex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_per_band_table = pd.pivot_table(results_df, values='SSIM', index=['Band'], \n",
    "                       columns=['Channels', 'Model'])\n",
    "\n",
    "print(ssim_per_band_table)\n",
    "reslatex = ssim_per_band_table.to_latex(float_format='{:,.3f}'.format)\n",
    "print(reslatex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 1: Dataset Examples\n",
    "###  1 Day - Full Disk Coverage, CONUS, and MESOSCALE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "month = 3\n",
    "day = 3\n",
    "year = 2018\n",
    "hour = 20\n",
    "channels = [1,2,3]\n",
    "#channels = [10]\n",
    "\n",
    "day_of_year = datetime(year, month, day).timetuple().tm_yday\n",
    "\n",
    "products = ['ABI-L1b-RadF', 'ABI-L1b-RadC', 'ABI-L1b-RadM']\n",
    "\n",
    "arrs = []\n",
    "for p in products:\n",
    "    prod = goes16s3.NOAAGOESS3(product=p, \n",
    "                               channels=channels)\n",
    "    prod_day_keys = prod.day_keys(year, day_of_year, hours=[hour])\n",
    "    prod_key = prod_day_keys.keyname[0]\n",
    "    minute = prod_day_keys.minute.min()\n",
    "    prod_minute_keys = prod_day_keys[prod_day_keys.minute == minute]\n",
    "\n",
    "    das = []\n",
    "    for c in channels:\n",
    "        k = prod_minute_keys[prod_minute_keys.channel == c].keyname.values[0]\n",
    "        ds, _ = prod.read_nc_from_s3(k)\n",
    "        da = ds.Rad\n",
    "        if c == 2:\n",
    "            da = utils.interp_da2d(da, 1./4, fillna=False)\n",
    "        elif c in [1,3,5]:\n",
    "            da = utils.interp_da2d(da, 1./2, fillna=False)\n",
    "        das.append(da)\n",
    "\n",
    "    arr = np.concatenate([d.values[np.newaxis] for d in das], axis=0)\n",
    "    arrs.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['fulldisk.png', 'conus.png', 'mesoscale.png']\n",
    "for i, arr in enumerate(arrs):\n",
    "    plt.imsave('figures/' + filenames[i],\n",
    "               arr.transpose(1,2,0)[:,:,[1,2,0]],\n",
    "               dpi=50)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2: Interpolation Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prod = goes16s3.NOAAGOESS3(product='ABI-L1b-RadM', channels=channels)\n",
    "\n",
    "ds = prod.read_day(year, day, hours=[hour]).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocked_data = utils.blocks(hour_das, width=352)\n",
    "B = blocked_data[0]\n",
    "\n",
    "I0_np = B.isel(t=0).values\n",
    "I0 = torch.from_numpy(I0_np[np.newaxis]).to(device)\n",
    "I1_np = B.isel(t=15).values\n",
    "I1 = torch.from_numpy(I1_np[np.newaxis]).to(device)\n",
    "\n",
    "\n",
    "print(I0.shape, I1.shape)\n",
    "\n",
    "f = flow_net(I0, I1)\n",
    "\n",
    "# x, y optical flows\n",
    "f_10 = f[:,:2]\n",
    "f_01 = f[:,2:]\n",
    "\n",
    "T = 4\n",
    "i = 2\n",
    "t = 1. * i / (T+1)\n",
    "# Input Channels: predicted image and warped without derivatives\n",
    "I_t, g0, g1 = interp_net(I0, I1, f_10, f_01, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = B.isel(t=i+1).values\n",
    "pred = I_t.cpu().detach().numpy()\n",
    "\n",
    "# Images to save\n",
    "# I0\n",
    "# I1 \n",
    "\n",
    "def make_img(I, f, vmin=None, vmax=None):\n",
    "    plt.imshow(I, vmin=vmin, vmax=vmax)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    scipy.misc.imsave(f, I)\n",
    "    \n",
    "make_img(I0_np[[1,2,0]].transpose(1,2,0), 'figures/I0.png')\n",
    "make_img(I1_np[[1,2,0]].transpose(1,2,0), 'figures/I1.png')\n",
    "make_img((I1_np-I0_np)[[1,2,0]].transpose(1,2,0), 'figures/I1-minus-I0.png')\n",
    "\n",
    "make_img(obs[[1,2,0]].transpose(1,2,0), 'figures/IT.png')\n",
    "\n",
    "\n",
    "f_10_np = f_10.cpu().detach().numpy()\n",
    "f_01_np = f_01.cpu().detach().numpy()\n",
    "\n",
    "#mn = np.percentile(f_10_np[0,1], 10.)\n",
    "#mx = np.percentile(f_10_np[0,1], 90.)\n",
    "\n",
    "f_10_np = f_10_np.mean(axis=(0,1))\n",
    "make_img(f_10_np[20:330,20:330], 'figures/f_10.png')#, vmin=mn, vmax=mx)\n",
    "\n",
    "f_01_np = f_01_np.mean(axis=(0,1))\n",
    "make_img(f_01_np[20:330,20:330], 'figures/f_01.png')#, vmin=mn, vmax=mx)\n",
    "\n",
    "print(g0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flow Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-03 00:00:00\n",
      "('Day', 62, 'Hour', 20)\n"
     ]
    }
   ],
   "source": [
    "dataset = goes16s3.NOAAGOESS3(product='ABI-L1b-RadM', \n",
    "                          channels=range(1,4))\n",
    "\n",
    "print(datetime(2018,3,3))\n",
    "hour_das = dataset.read_day(year, datetime(2018, 3, 3).timetuple().tm_yday, \n",
    "                            hours=[20]).next() # N,12or13,512,512,3\n",
    "blocked_data = utils.blocks(hour_das, width=352)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint ./saved-models/5Min-3Channels/checkpoint.flownet.pth.tar\n",
      "=> loaded checkpoint './saved-models/5Min-3Channels/checkpoint.flownet.pth.tar' (epoch 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "def opticalflow(flow):\n",
    "    hsv = np.ones((flow.shape[0], flow.shape[1], 3))*255.\n",
    "    \n",
    "    # Use Hue, Saturation, Value colour model \n",
    "    mag, ang = cv2.cartToPolar(flow[:,:, 0], flow[:,:, 1])\n",
    "    \n",
    "    hsv[:,:, 0] = ang * 180 / np.pi / 2\n",
    "    hsv[:,:, 2] = cv2.normalize(mag, None, 0, 255., cv2.NORM_MINMAX)\n",
    "    bgr = cv2.cvtColor(np.uint8(hsv), cv2.COLOR_HSV2BGR)\n",
    "    return bgr\n",
    "\n",
    "def flowfigures(block):\n",
    "    n_channels = 3\n",
    "    model_path = './saved-models/5Min-3Channels/'\n",
    "    flownet, interpnet, warper = load_models(n_channels, model_path, False)\n",
    "        \n",
    "    block_vals = torch.from_numpy(block.values)\n",
    "    N = block_vals.shape[0]\n",
    "    idxs = np.arange(0, N+1, 5)\n",
    "    preds = []\n",
    "    \n",
    "    idx0 = 0\n",
    "    idx1 = 5\n",
    "\n",
    "    j = 2\n",
    "    t = 1. * j / 5\n",
    "    \n",
    "    I0 = torch.unsqueeze(block_vals[idx0], 0).to(device)\n",
    "    I1 = torch.unsqueeze(block_vals[idx1], 0).to(device)\n",
    "    IT_img = block_vals[idx0 + j].detach().cpu().numpy().transpose(1,2,0)\n",
    "    \n",
    "    f = flownet(I0, I1)\n",
    "\n",
    "    f_01 = f[:,:2]\n",
    "    f_10 = f[:,2:]\n",
    "\n",
    "    I_t, g0, g1, V_t0, V_t1, delta_f_t0, delta_f_t1 = interpnet(I0, I1, f_01, f_10, t)\n",
    "    F_t0_hat = -(1-t) * t * f_01 + t**2 * f_10\n",
    "    F_t1_hat =  (1-t) ** 2 * f_01 - t * (1 - t) * f_10\n",
    "    F_t0 = F_t0_hat + delta_f_t0\n",
    "    F_t1 = F_t1_hat + delta_f_t1\n",
    "    \n",
    "    \n",
    "    detach = lambda x: x.detach().cpu().numpy()[0].transpose(1,2,0)\n",
    "    \n",
    "    I0_img = detach(I0)\n",
    "    I1_img = detach(I1)\n",
    "    plt.imsave('figures/flowfigs/I0.png', I0_img)\n",
    "    plt.imsave('figures/flowfigs/I1.png', I1_img)\n",
    "\n",
    "    \n",
    "    V_t0_img = detach(V_t0)\n",
    "    plt.imsave('figures/flowfigs/V_t0.png', V_t0_img[:,:,0], cmap='gray')\n",
    "    V_t1_img = detach(V_t1)\n",
    "    plt.imsave('figures/flowfigs/V_t1.png', V_t1_img[:,:,0], cmap='gray')\n",
    "    plt.imsave('figures/flowfigs/V_tdiff.png', V_t1_img[:,:,0] - V_t0_img[:,:,0], cmap='gray')\n",
    "\n",
    "    f_01_img = opticalflow(detach(F_t0)[20:332,30:332])\n",
    "    plt.imsave('figures/flowfigs/F_t0.png', f_01_img)\n",
    "    f_10_img = opticalflow(detach(F_t1)[20:332,30:332])\n",
    "    plt.imsave('figures/flowfigs/F_t1.png', f_10_img)\n",
    "    \n",
    "    I_t_img = detach(I_t)\n",
    "    plt.imsave('figures/flowfigs/I_t.png', I_t_img)\n",
    "    diff = IT_img - I_t_img\n",
    "    plt.imsave('figures/flowfigs/residual.png', diff*5)\n",
    "    \n",
    "    \n",
    "flowfigures(blocked_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Average PSNR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
